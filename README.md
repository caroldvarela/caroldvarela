# üëã Hello! I'm Carol Dayana Varela Cortez

<div align="center">
  
**üöÄ Passionate Data Engineer**

*Transforming complex data into actionable insights for enterprise decision-making*

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/carol-varela)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:carol.varela@uao.edu.co)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/caroldvarela)

**üìç Location:** Colombia üá®üá¥

</div>

---

## üéØ About Me

I'm a **Data Engineer** with solid experience in developing enterprise-level ETL/ELT pipelines, modern data architectures, and Business Intelligence solutions. I specialize in cloud technologies like **Databricks**, **Snowflake**, **Apache Airflow**, **dbt**, and **Delta Lake**.

### üåü My Strengths
- **Data Lakehouse Architectures** with Medallion patterns (Bronze-Silver-Gold)
- **Workflow Orchestration** with Apache Airflow and Astronomer Cosmos
- **Data Transformation** with dbt and advanced SQL
- **Real-time Data Streaming** with Apache Kafka
- **Visualization** with Power BI and BI tools
- **Containerization** with Docker and cloud deployment

---

## üõ†Ô∏è Technology Stack

### **Programming Languages**
![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-4479A1?style=flat&logo=postgresql&logoColor=white)
![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=flat&logo=apache-spark&logoColor=white)

### **Cloud Platforms & Data Warehouses**
![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=flat&logo=databricks&logoColor=white)
![Snowflake](https://img.shields.io/badge/Snowflake-29B5E8?style=flat&logo=snowflake&logoColor=white)


### **Orchestration Tools**
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=flat&logo=apacheairflow&logoColor=white)
![Astronomer](https://img.shields.io/badge/Astronomer-000000?style=flat&logo=astronomer&logoColor=white)
![dbt](https://img.shields.io/badge/dbt-FF694B?style=flat&logo=dbt&logoColor=white)

### **Databases & Storage**
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=flat&logo=postgresql&logoColor=white)
![Delta Lake](https://img.shields.io/badge/Delta%20Lake-009639?style=flat&logo=delta&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=flat&logo=apache-kafka&logoColor=white)

### **BI & Visualization**
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?style=flat&logo=powerbi&logoColor=black)
![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=flat&logo=jupyter&logoColor=white)

### **DevOps & Containerization**
![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)
![Git](https://img.shields.io/badge/Git-F05032?style=flat&logo=git&logoColor=white)

---
## üìú Certifications

- **Databricks Fundamentals** ‚Äî Certified in *2025* 
- **Databricks Certified Data Engineer Associate** ‚Äî Certified in *2025* 

---

## üöÄ Featured Projects

### üèóÔ∏è **Data Lakehouse Platform with CDC/SCD - Databricks + dbt**
![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=flat&logo=databricks&logoColor=white)
![Delta Lake](https://img.shields.io/badge/Delta%20Lake-009639?style=flat&logo=delta&logoColor=white)
![dbt](https://img.shields.io/badge/dbt-FF694B?style=flat&logo=dbt&logoColor=white)

**Modern data architecture with incremental processing and data quality**

- ‚úÖ Implemented complete **Data Lakehouse** architecture following the **Medallion (Bronze-Silver-Gold)** pattern
- ‚úÖ Developed **CDC (Change Data Capture)** and **SCD Type 1** pipelines for slowly changing dimensions
- ‚úÖ Created **10 analytical models** in dbt to answer critical business questions
- ‚úÖ Implemented **Autoloader** for automated CSV data ingestion with flexible schemas

[üìÅ View Project](https://github.com/caroldvarela/databricks-dbt-lakehouse)

---

### üö¥‚Äç‚ôÇÔ∏è **Data Warehouse with Snowflake + dbt + Astronomer Cosmos**
![Snowflake](https://img.shields.io/badge/Snowflake-29B5E8?style=flat&logo=snowflake&logoColor=white)
![dbt](https://img.shields.io/badge/dbt-FF694B?style=flat&logo=dbt&logoColor=white)
![Astronomer](https://img.shields.io/badge/Astronomer-000000?style=flat&logo=astronomer&logoColor=white)

**Modern data warehouse architecture with automated orchestration**

- ‚úÖ Implemented complete **data warehouse** with Snowflake using star schema
- ‚úÖ Integrated **dbt with Astronomer Cosmos** for automatic DAG generation
- ‚úÖ Created optimized **dimensional models** (dim_customer, dim_product, fact_orders)
- ‚úÖ Developed automated **quality tests** with dbt

[üìÅ View Project](https://github.com/caroldvarela/dbt-snowflake)

---

### ‚ö° **Advanced ETL Pipeline with Real-Time Streaming**
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=flat&logo=apacheairflow&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=flat&logo=apache-kafka&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=flat&logo=postgresql&logoColor=white)
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?style=flat&logo=powerbi&logoColor=black)

**Comprehensive data engineering solution with orchestration and visualization**

- ‚úÖ Designed a **hybrid (batch + streaming) data architecture** with Apache Airflow, Kafka, and PostgreSQL to centralize and process cardiovascular risk factor data  
- ‚úÖ Implemented **automated data quality validations** with Great Expectations and applied **dimensional modeling** for analytical consistency  
- ‚úÖ Integrated **multiple data sources** (local datasets + Our World in Data APIs) with advanced transformations and schema harmonization  
- ‚úÖ Enabled **near real-time dashboards** in Power BI with < 3-second latency for continuous monitoring  
- ‚úÖ Containerized the entire workflow with **Docker Compose** for reproducible and scalable deployments  

[üìÅ View Project](https://github.com/caroldvarela/ETL-1)

---

### üéµ **Music Analytics Platform - Spotify & Grammy Awards**
![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=flat&logo=apacheairflow&logoColor=white)
![Google Drive API](https://img.shields.io/badge/Google%20Drive%20API-4285F4?style=flat&logo=google-drive&logoColor=white)

**ETL pipeline and music industry analysis**

- ‚úÖ Integrated **Spotify API** and **Grammy Awards** data with intelligent matching algorithms
- ‚úÖ Implemented **OAuth 2.0 authentication** for Google Drive API
- ‚úÖ Created **dual storage strategy** (database + cloud storage)
- ‚úÖ Developed **sophisticated transformations** with fuzzy string matching

[üìÅ View Project](https://github.com/caroldvarela/workshop-02)

---

### ü§ñ **Happiness Prediction System with Machine Learning**
![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=flat&logo=apache-kafka&logoColor=white)

**ML pipeline with streaming and prediction storage**

- ‚úÖ Developed **regression model (Random Forest)** to predict happiness scores by country
- ‚úÖ Implemented complete **ML pipeline** (EDA ‚Üí training ‚Üí evaluation ‚Üí prediction)
- ‚úÖ Created **streaming system** with Kafka for real-time processing
- ‚úÖ Stored **predictions and metrics** in database for further analysis

[üìÅ View Project](https://github.com/caroldvarela/workshop-03)

---

### üìä **ETL Workshop - Candidate Analysis**
![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=flat&logo=postgresql&logoColor=white)
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?style=flat&logo=powerbi&logoColor=black)

**Data migration and exploratory analysis project**

- ‚úÖ Migrated **50,000 candidate records** from CSV to PostgreSQL using SQLAlchemy
- ‚úÖ Performed complete **EDA** identifying patterns and correlations
- ‚úÖ Created **data transformations** including technology categorization
- ‚úÖ Developed **dashboards** in Power BI for hiring metrics visualization

[üìÅ View Project](https://github.com/caroldvarela/workshop-01)

---

## üìà GitHub Statistics

<div align="center">

![GitHub Stats](https://github-readme-stats.vercel.app/api?username=caroldvarela&show_icons=true&theme=tokyonight&hide_border=true&count_private=true)

![Top Languages](https://github-readme-stats.vercel.app/api/top-langs/?username=caroldvarela&layout=compact&theme=tokyonight&hide_border=true)

![GitHub Streak](https://github-readme-streak-stats.herokuapp.com/?user=caroldvarela&theme=tokyonight&hide_border=true)

</div>

---

## üåü Key Strengths

- **üß† Analytical Thinking**: Ability to transform business problems into technical solutions
- **üë• Team Collaboration**: Experience in multidisciplinary collaborative projects  
- **üìö Continuous Learning**: Constant updating with emerging technologies
- **üìù Documentation**: Focus on clean code and comprehensive documentation
- **üîß Problem Solving**: Ability to debug and optimize complex systems

